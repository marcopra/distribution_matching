# @package agent
_target_: agent.rover.RoverAgent
name: dist_matching
obs_type: ??? # to be specified later
obs_shape: ??? # to be specified later
action_shape: ??? # to be specified later
lr_actor: 10 # eta
discount: ${discount} # gamma
lambda_reg: 1e-3
lr_T: 1e-3
batch_size: 1024
batch_size_actor: 8100
nstep: 1
lr_encoder: 1e-3
curl: true
embedding_sum_loss: 0.0
hidden_dim: 1024
feature_dim: null
T_init_steps: 1000
update_every_steps: 1
update_actor_every_steps: 1500
pmd_steps: 100
pmd_eta_mode: none # [none, adagrad, backtracking]
pmd_best_iterate: true
pmd_grad_clip_norm: 0.0
pmd_adagrad_eps: 1e-8
pmd_eta_min: 1e-8
pmd_eta_max: 1e3
pmd_backtrack_factor: 0.5
pmd_backtrack_max_trials: 8
sink_schedule: "linear(0.0, 0.005, 100_000)"
epsilon_schedule: 0.15
mode: l1 # [l1, l2]
reward: false # whether to learn a reward predictor or not
embeddings: true  # whether to use embeddings or not, if obs_type is pixels this is always true
use_tb: ${use_tb}
use_wandb: ${use_wandb}
num_expl_steps: ??? # to be specified later
device: ${device}
