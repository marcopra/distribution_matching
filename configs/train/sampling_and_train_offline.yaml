# @package _global_
defaults:
  - /agent: cql
  - /env: pong
  # - override hydra/launcher: submitit_local
  

# mode
reward_free: false
# task settings
domain: gym
task_name:  ${env.name}
obs_type: pixels # [discrete_states, states, pixels]
frame_stack: 3 # only works if obs_type=pixels
action_repeat: 4 # set to 2 for pixels
discount: 0.99
resolution: 84  
random_init: true
random_goal: true
# agent settings
pretrained_path: null
# agent:
#   update_every_steps: 1
#   nstep: 1
# train settings
num_train_frames: 600_000
# num_seed_frames_array: [601, 1201, 2401, 3601, 4801, 6001, 7201, 8401, 9601, 10801, 12001, 13201, 14401, 15601, 16801, 18001, 20001] # number of seed frames for each cycle
num_seed_frames_array: [400_000] # number of seed frames for each cycle
num_seed_frames: null # will be set dynamically in the code
# eval
eval_every_frames: 1000
num_eval_episodes: 5
num_eval_dp_episodes: 10
# pretrained
snapshot_ts: 0 #100000
snapshot_base_dir: ./pretrained_models
# replay buffer
replay_buffer_size: 1000000
replay_buffer_num_workers: 1
batch_size: ${agent.batch_size}
nstep: ${agent.nstep}
update_encoder: false # can be either true or false depending if we want to fine-tune encoder
# misc
seed: 1
device: cuda
save_video: true
save_train_video: false
use_tb: true
use_wandb: false
wandb_id: null
wandb_project: "offline_rl"
wandb_entity: "urlb"
wandb_tag: none
wandb_run_name: ${now:%Y.%m.%d}_${now:%H%M}_gym_${task_name}
# experiment
experiment: exp


hydra:
  run:
    dir: ./exp_local/${now:%Y.%m.%d}/${now:%H%M%S}_${agent.name}_${experiment}
  sweep:
    dir: ./exp_sweep/${now:%Y.%m.%d}/${now:%H%M}_${agent.name}_${experiment}
    subdir: ${hydra.job.num}
  # launcher:
  #   timeout_min: 4300
  #   cpus_per_task: 10
  #   gpus_per_node: 1
  #   tasks_per_node: 1
  #   mem_gb: 160
  #   nodes: 1
  #   submitit_folder: ./exp_sweep/${now:%Y.%m.%d}/${now:%H%M}_${agent.name}_${experiment}/.slurm
