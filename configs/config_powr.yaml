# Main configuration for distribution matching experiments
defaults:
  - env: four_rooms  # Options: single_room, two_rooms, four_rooms
  - _self_

# Experiment hyperparameters
name: 'powr'  # Nome dell'esperimento
# Optimization parameters
gamma: 0.999  # Discount factor for occupancy measure
eta: 1 # Learning rate for mirror descent

# Training parameters
pmd_iter_updates: 10 # Number of optimization updates
eval_episodes: 10  # Number of evaluation episodes
timestep_interval: 500  # Timesteps between evaluations
timesteps: 8000  # Total training timesteps

# Random seed
seed: 42
n_runs: 7  # Number of experiment runs with different seeds

p_path: null  # Path to pretrained policy (if any)

# Weights & Biases configuration
wandb:
  use_wandb: false  # Set to false to disable wandb logging
  wandb_project: 'distribution_matching'  # Nome del progetto wandb
  wandb_run_name: ${name}_${hydra:runtime.choices.env}_${now:%Y-%m-%d}_${now:%H-%M-%S}
  wandb_id: null  # ID per riprendere un run esistente (null per nuovo run)
  wandb_tag: null  # Tags separati da underscore (es: 'powr_four_rooms')

# Output paths
output:
  save_dir: '/home/mprattico/distribution_matching'
  results_uniform: '${output.save_dir}/distribution_matching_results_uniform.png'
  results_optimized: '${output.save_dir}/distribution_matching_results.png'
  trajectory_uniform: '${output.save_dir}/trajectory_uniform_policy.png'
  trajectory_optimized: '${output.save_dir}/trajectory_optimized_policy.png'
  results_prefix: '${output.save_dir}/distribution_matching_results'

# Hydra configuration for output directory structure
hydra:
  run:
    dir: outputs/${name}/${hydra:runtime.choices.env}/${now:%Y-%m-%d}/${now:%H-%M-%S}
  sweep:
    dir: outputs/${name}/${hydra:runtime.choices.env}/${now:%Y-%m-%d}/${now:%H-%M-%S}
    subdir: ${hydra.job.num}
